load-data-from-Cloud-Storage-into-BigQuery

1. In the Console, on the Navigation menu (Navigation menu) click BigQuery then click Done.

2. Create a new dataset within your project by selecting your project in the Resources section, then clicking on CREATE DATASET on the right.

3. In the Create Dataset dialog, for Dataset ID, type logdata.

4. For Data location, select the continent closest to the region your project was created in. click Create dataset.

5. Create a new table in the logdata to store the data from the CSV file.

6. Click on Create Table. On the Create Table page, in the Source section:

	For Create table from, choose select Google Cloud Storage, and in the field, type gs://cloud-training/gcpfci/access_log.csv.
	Verify File format is set to CSV.
	Note: When you have created a table previously, the Create from Previous Job option allows you to quickly use your settings to create similar tables.

7. In the Destination section:

	For Dataset name, leave logdata selectedx.
	For Table name, type accesslogx.
	For Table type, Native table should be selected.

8. Under Schema section, for Auto detect check the Schema and input Parameters.

9. Accept the remaining default values and click Create Table.

	BigQuery creates a load job to create the table and upload data into the table (this may take a few seconds).

10. (Optional) To track job progress, click Job History.

11. When the load job is complete, click logdata > accesslog.

12. On the table details page, click Details to view the table properties, and then click Preview to view the table data.
	Each row in this table logs a hit on a web server. The first field, string_field_0, is the IP address of the client. The fourth through ninth fields log the day, month, year, hour, minute, and second at which the hit occurred. In this activity, you will learn about the daily pattern of load on this web server.


Perform a query on the data using the BigQuery web UI

In the Query editor window, type (or copy-and-paste) the following query:

Because you told BigQuery to automatically discover the schema when you load the data, the hour of the day during which each web hit arrived is in a field called int_field_6.

select int64_field_6 as hour, count(*) as hitcount from logdata.accesslog
group by hour
order by hour

Notice that the Query Validator tells you that the query syntax is valid (indicated by the green check mark) and indicates how much data the query will process. 